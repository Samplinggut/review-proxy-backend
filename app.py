# -*- coding: utf-8 -*-
"""FYP_FINAL_CODE.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1W61GKtkodXxqn2JjaGo2aOP-y3yBe7bS
"""

import pandas as pd
import numpy as np
import gradio as gr
import joblib
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, balanced_accuracy_score
from sklearn.utils.class_weight import compute_sample_weight
from imblearn.over_sampling import SMOTE
import re
from collections import Counter

# Sentiment dictionary approach
POSITIVE_WORDS = set(["excellent", "amazing", "great", "comfortable", "happy", "love", "fantastic", "good", "best", "wonderful", "satisfactory", "pleasant", "enjoyable"])
NEGATIVE_WORDS = set(["bad", "terrible", "horrible", "uncomfortable", "awful", "poor", "disappointed", "worst", "regret", "pain", "mediocre", "boring"])

# ---------------------- Step 1: Load and Clean Data ----------------------
df = pd.read_csv("/content/fyp_transformed_dataset.csv")

def clean_text(text):
    text = str(text).lower()  # Convert to lowercase
    text = re.sub(r'[^a-z0-9 ]', '', text)  # Remove special characters
    text = re.sub(r'\s+', ' ', text).strip()  # Remove extra spaces
    return text

df["reviews"] = df["reviews"].fillna("").apply(clean_text)
df['combined_text'] = df['review_title'].fillna('') + ' ' + df['reviews'].fillna('')

# Define Fake vs. Real Label
df["Fake_Real_Label"] = df["User Credibility Score"].apply(lambda x: 1 if x > 30 else 0)

# Define Sentiment Label (for Real Reviews only)
df["Sentiment_Label"] = df.apply(lambda row: 1 if row["rating"] >= 3 else 0, axis=1)

# ---------------------- Step 2: Feature Engineering ----------------------
tfidf = TfidfVectorizer(max_features=2000, ngram_range=(1, 3))
X_reviews = tfidf.fit_transform(df["reviews"]).toarray()

# ---------------------- Step 3: Train Fake vs. Real Classifier ----------------------
y_fake_real = df["Fake_Real_Label"]
X_train, X_test, y_train, y_test = train_test_split(X_reviews, y_fake_real, test_size=0.2, random_state=42)

smote = SMOTE(sampling_strategy=0.5, random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

rf_classifier = RandomForestClassifier(n_estimators=150, max_depth=12, min_samples_split=5, random_state=42)
rf_classifier.fit(X_train_resampled, y_train_resampled)

# --------- Evaluate Fake vs. Real Classifier ---------
y_pred_rf = rf_classifier.predict(X_test)
accuracy_rf = accuracy_score(y_test, y_pred_rf)

# ---------------------- Step 4: Train Sentiment Classifier ----------------------
df_real_reviews = df[df["Fake_Real_Label"] == 1]
y_sentiment = df_real_reviews["Sentiment_Label"]
X_sentiment = X_reviews[df["Fake_Real_Label"] == 1]

X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X_sentiment, y_sentiment, test_size=0.25, random_state=42)

sample_weights = compute_sample_weight('balanced', y_train_s)
sentiment_classifier = XGBClassifier(n_estimators=60, max_depth=3, learning_rate=0.07, reg_alpha=1.0, reg_lambda=1.2)
sentiment_classifier.fit(X_train_s, y_train_s, sample_weight=sample_weights)

# --------- Evaluate Sentiment Classifier ---------
y_pred_sent = sentiment_classifier.predict(X_test_s)
accuracy_sent = accuracy_score(y_test_s, y_pred_sent)

# ---------------------- Step 5: Save Everything in One Model File ----------------------
model_bundle = {
    "fake_review_classifier": rf_classifier,
    "sentiment_classifier": sentiment_classifier,
    "tfidf_vectorizer": tfidf,
    "fake_review_accuracy": accuracy_rf,
    "sentiment_classifier_accuracy": accuracy_sent
}

joblib.dump(model_bundle, "/content/fake_review_model.pkl")

# ---------------------- Step 6: Load & Use the Model in Gradio ----------------------
loaded_model = joblib.load("/content/fake_review_model.pkl")
rf_classifier = loaded_model["fake_review_classifier"]
sentiment_classifier = loaded_model["sentiment_classifier"]
tfidf = loaded_model["tfidf_vectorizer"]

def classify_review(review):
    review_cleaned = clean_text(review)
    review_tfidf = tfidf.transform([review_cleaned]).toarray()
    fake_real_pred = rf_classifier.predict(review_tfidf)[0]

    # Dictionary-based Sentiment Analysis
    words = set(review_cleaned.split())
    pos_count = len(words & POSITIVE_WORDS)
    neg_count = len(words & NEGATIVE_WORDS)

    if pos_count > neg_count:
        sentiment_pred = 1  # Positive
    elif neg_count > pos_count:
        sentiment_pred = 0  # Negative
    else:
        sentiment_pred = sentiment_classifier.predict(review_tfidf)[0] if fake_real_pred == 1 else "N/A"

    return "Fake" if fake_real_pred == 0 else "Real", "Positive" if sentiment_pred == 1 else "Negative"

# ---------------------- Gradio UI ----------------------
with gr.Blocks() as interface:
    gr.Markdown("#  Fake Review & Sentiment Analysis Extension")

    review_input = gr.Textbox(label="Enter a Review")
    fake_real_label = gr.Label(label=" Fake or Real")
    sentiment_label = gr.Label(label=" Sentiment")
    analyze_review_button = gr.Button(" Classify Review")
    analyze_review_button.click(classify_review, inputs=[review_input], outputs=[fake_real_label, sentiment_label])

    accuracy_fake = gr.Textbox(label="Fake Review Classifier Accuracy", interactive=False, value=f"{accuracy_rf * 100:.2f}%")
    accuracy_sentiment = gr.Textbox(label="Sentiment Classifier Accuracy", interactive=False, value=f"{accuracy_sent * 100:.2f}%")

interface.launch()

import matplotlib.pyplot as plt
from sklearn.metrics import precision_recall_curve, auc

# Predict probabilities for the test set
y_scores = rf_classifier.predict_proba(X_test)[:, 1]

# Compute precision, recall, and thresholds
precision, recall, thresholds = precision_recall_curve(y_test, y_scores)
pr_auc = auc(recall, precision)

# Plotting the Precision-Recall Curve
plt.figure(figsize=(8, 6))
plt.plot(recall, precision, label=f'PR Curve (AUC = {pr_auc:.2f})')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve for Fake vs. Real Classifier')
plt.legend()
plt.grid(True)
plt.show()

# Fake vs. Real Classifier
train_accuracy_rf = accuracy_score(y_train_resampled, rf_classifier.predict(X_train_resampled))
print(f"Training Accuracy (Fake vs. Real): {train_accuracy_rf * 100:.2f}%")
print(f"Testing Accuracy (Fake vs. Real): {accuracy_rf * 100:.2f}%")

# Sentiment Classifier
train_accuracy_sent = accuracy_score(y_train_s, sentiment_classifier.predict(X_train_s))
print(f"Training Accuracy (Sentiment): {train_accuracy_sent * 100:.2f}%")
print(f"Testing Accuracy (Sentiment): {accuracy_sent * 100:.2f}%")

from sklearn.metrics import balanced_accuracy_score

# Calculate Balanced Accuracy
balanced_acc_rf = balanced_accuracy_score(y_test, y_pred_rf)

print(f"Balanced Accuracy (Fake vs. Real): {balanced_acc_rf * 100:.2f}%")

import gradio as gr
import joblib
import requests
from bs4 import BeautifulSoup
import pandas as pd
import re
import threading
from queue import Queue
from sklearn.feature_extraction.text import TfidfVectorizer

# Load trained model
model_bundle = joblib.load("fake_review_model.pkl")
rf_classifier = model_bundle["fake_review_classifier"]
sentiment_classifier = model_bundle["sentiment_classifier"]
tfidf = model_bundle["tfidf_vectorizer"]

# Sentiment dictionary
POSITIVE_WORDS = set(["excellent", "amazing", "great", "comfortable", "happy", "love", "fantastic", "good", "best", "wonderful"])
NEGATIVE_WORDS = set(["bad", "terrible", "horrible", "uncomfortable", "awful", "poor", "disappointed", "worst", "regret", "pain"])

# Text cleaning function
def clean_text(text):
    text = str(text).lower()
    text = re.sub(r'[^a-z0-9 ]', '', text)  # Remove special characters
    text = re.sub(r'\s+', ' ', text).strip()  # Remove extra spaces
    return text

# Generalized Scraper Function
def scrape_reviews(url, max_reviews=20):
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
        "Accept-Language": "en-US,en;q=0.9",
        "Accept-Encoding": "gzip, deflate, br",
        "Connection": "keep-alive"
    }

    try:
        response = requests.get(url, headers=headers, timeout=10)
        if response.status_code != 200:
            return f"Failed to fetch page (Status Code: {response.status_code})"

        soup = BeautifulSoup(response.text, "lxml")

        possible_selectors = [
            ".review-text",
            "[data-hook='review-body']",
            ".review-content",
            ".review-body",
            ".comment",
            ".review-text-content"
        ]

        reviews = []
        for selector in possible_selectors:
            reviews = [review.get_text(strip=True) for review in soup.select(selector)]
            if reviews:
                break

        if not reviews:
            return "No reviews found on this page. Try a different URL."

        return reviews[:max_reviews]

    except Exception as e:
        return f"Error occurred: {str(e)}"

# Function to classify reviews using threads
def classify_reviews_batch(reviews):
    results = []
    queue = Queue()

    def classify_worker(review):
        fake_real, sentiment = classify_review(review)
        queue.put((review[:150] + "...", fake_real, sentiment))

    threads = []
    for review in reviews:
        thread = threading.Thread(target=classify_worker, args=(review,))
        threads.append(thread)
        thread.start()

    for thread in threads:
        thread.join()

    while not queue.empty():
        results.append(queue.get())

    return pd.DataFrame(results, columns=["Review", "Fake/Real", "Sentiment"])

# Function to classify a single review
def classify_review(review):
    review_cleaned = clean_text(review)
    review_tfidf = tfidf.transform([review_cleaned]).toarray()
    fake_real_pred = rf_classifier.predict(review_tfidf)[0]

    words = set(review_cleaned.split())
    pos_count = len(words & POSITIVE_WORDS)
    neg_count = len(words & NEGATIVE_WORDS)

    if pos_count > neg_count:
        sentiment_pred = 1
    elif neg_count > pos_count:
        sentiment_pred = 0
    else:
        sentiment_pred = sentiment_classifier.predict(review_tfidf)[0] if fake_real_pred == 1 else "N/A"

    return "Fake" if fake_real_pred == 0 else "Real", "Positive" if sentiment_pred == 1 else "Negative"

# Main function for analyzing reviews from a product URL
def analyze_product_reviews(url):
    reviews = scrape_reviews(url)

    if isinstance(reviews, str):
        return reviews, None, None

    df_results = classify_reviews_batch(reviews)

    fake_count = (df_results["Fake/Real"] == "Fake").sum()
    real_count = (df_results["Fake/Real"] == "Real").sum()
    pos_count = (df_results["Sentiment"] == "Positive").sum()
    neg_count = (df_results["Sentiment"] == "Negative").sum()

    total_reviews = len(df_results)

    summary_text = f"""
     **Review Analysis Summary**
    - **Total Reviews Analyzed:** {total_reviews}
    - **Fake Reviews:** {fake_count} ({(fake_count / total_reviews) * 100:.2f}%)
    - **Real Reviews:** {real_count} ({(real_count / total_reviews) * 100:.2f}%)
    - **Positive Sentiment:** {pos_count} ({(pos_count / total_reviews) * 100:.2f}%)
    - **Negative Sentiment:** {neg_count} ({(neg_count / total_reviews) * 100:.2f}%)
    """

    return df_results, summary_text, f" Analysis Complete! {total_reviews} reviews processed."

# Gradio UI
with gr.Blocks() as interface:
    gr.Markdown("#  Fake Review & Sentiment Analysis from Product URL (Optimized)")

    product_url_input = gr.Textbox(label="Enter Product URL")
    analyze_button = gr.Button(" Analyze Reviews")

    results_output = gr.Dataframe(headers=["Review", "Fake/Real", "Sentiment"])
    summary_output = gr.Markdown()
    completion_message = gr.Textbox(label="Status", interactive=False)

    analyze_button.click(analyze_product_reviews, inputs=[product_url_input], outputs=[results_output, summary_output, completion_message])

interface.launch()

import gradio as gr
import joblib
import requests
from bs4 import BeautifulSoup
import pandas as pd
import re
import threading
from queue import Queue
from sklearn.feature_extraction.text import TfidfVectorizer

# Load trained model
model_bundle = joblib.load("fake_review_model.pkl")
rf_classifier = model_bundle["fake_review_classifier"]
sentiment_classifier = model_bundle["sentiment_classifier"]
tfidf = model_bundle["tfidf_vectorizer"]

# Sentiment dictionary
POSITIVE_WORDS = set(["excellent", "amazing", "great", "comfortable", "happy", "love", "fantastic", "good", "best", "wonderful"])
NEGATIVE_WORDS = set(["bad", "terrible", "horrible", "uncomfortable", "awful", "poor", "disappointed", "worst", "regret", "pain"])

# Clean text
def clean_text(text):
    text = str(text).lower()
    text = re.sub(r'[^a-z0-9 ]', '', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text

# Scrape reviews
def scrape_reviews(url, max_reviews=20):
    headers = {
        "User-Agent": "Mozilla/5.0",
        "Accept-Language": "en-US,en;q=0.9",
    }

    try:
        response = requests.get(url, headers=headers, timeout=10)
        if response.status_code != 200:
            return f"Failed to fetch page (Status Code: {response.status_code})"

        soup = BeautifulSoup(response.text, "lxml")

        selectors = [
            ".review-text",
            "[data-hook='review-body']",
            ".review-content",
            ".review-body",
            ".comment",
            ".review-text-content"
        ]

        reviews = []
        for selector in selectors:
            reviews = [r.get_text(strip=True) for r in soup.select(selector)]
            if reviews:
                break

        if not reviews:
            return "No reviews found on this page. Try a different URL."

        return reviews[:max_reviews]

    except Exception as e:
        return f"Error occurred: {str(e)}"

# Classify review
def classify_review(review):
    review_cleaned = clean_text(review)
    review_tfidf = tfidf.transform([review_cleaned]).toarray()
    fake_real_pred = rf_classifier.predict(review_tfidf)[0]

    words = set(review_cleaned.split())
    pos_count = len(words & POSITIVE_WORDS)
    neg_count = len(words & NEGATIVE_WORDS)

    if pos_count > neg_count:
        sentiment_pred = 1
    elif neg_count > pos_count:
        sentiment_pred = 0
    else:
        sentiment_pred = sentiment_classifier.predict(review_tfidf)[0] if fake_real_pred == 1 else "N/A"

    return "Fake" if fake_real_pred == 0 else "Real", "Positive" if sentiment_pred == 1 else "Negative"

# Classify multiple
def classify_reviews_batch(reviews):
    results = []
    queue = Queue()

    def classify_worker(review):
        fake_real, sentiment = classify_review(review)
        queue.put((review[:150] + "...", fake_real, sentiment))

    threads = []
    for review in reviews:
        thread = threading.Thread(target=classify_worker, args=(review,))
        threads.append(thread)
        thread.start()

    for thread in threads:
        thread.join()

    while not queue.empty():
        results.append(queue.get())

    return pd.DataFrame(results, columns=["Review", "Fake/Real", "Sentiment"])

# Function for full analysis
def analyze_product_reviews(url):
    reviews = scrape_reviews(url)

    if isinstance(reviews, str):
        return reviews, None, None

    df_results = classify_reviews_batch(reviews)

    fake_count = (df_results["Fake/Real"] == "Fake").sum()
    real_count = (df_results["Fake/Real"] == "Real").sum()
    pos_count = (df_results["Sentiment"] == "Positive").sum()
    neg_count = (df_results["Sentiment"] == "Negative").sum()

    total_reviews = len(df_results)

    summary_text = f"""
     **Review Analysis Summary**
    - **Total Reviews Analyzed:** {total_reviews}
    - **Fake Reviews:** {fake_count} ({(fake_count / total_reviews) * 100:.2f}%)
    - **Real Reviews:** {real_count} ({(real_count / total_reviews) * 100:.2f}%)
    - **Positive Sentiment:** {pos_count} ({(pos_count / total_reviews) * 100:.2f}%)
    - **Negative Sentiment:** {neg_count} ({(neg_count / total_reviews) * 100:.2f}%)
    """

    return df_results, summary_text, f" Analysis Complete! {total_reviews} reviews processed."

# JSON endpoint for extension
def analyze_reviews_json(url):
    reviews = scrape_reviews(url)

    if isinstance(reviews, str):
        return { "error": reviews }

    df_results = classify_reviews_batch(reviews)

    fake_count = (df_results["Fake/Real"] == "Fake").sum()
    real_count = (df_results["Fake/Real"] == "Real").sum()
    pos_count = (df_results["Sentiment"] == "Positive").sum()
    neg_count = (df_results["Sentiment"] == "Negative").sum()

    total_reviews = len(df_results)

    return {
        "total": total_reviews,
        "real": int(real_count),
        "fake": int(fake_count),
        "positive": int(pos_count),
        "negative": int(neg_count)
    }

# Gradio UI (for humans)
with gr.Blocks() as ui_interface:
    gr.Markdown("# 🕵️‍♂️ Fake Review & Sentiment Analyzer")

    url_input = gr.Textbox(label="Enter Product URL")
    analyze_btn = gr.Button("Analyze Reviews")

    result_df = gr.Dataframe(headers=["Review", "Fake/Real", "Sentiment"])
    summary_md = gr.Markdown()
    status = gr.Textbox(label="Status", interactive=False)

    analyze_btn.click(analyze_product_reviews, inputs=url_input, outputs=[result_df, summary_md, status])

# Gradio JSON endpoint (for extension)
json_interface = gr.Interface(fn=analyze_reviews_json, inputs="text", outputs="json")

# Launch both
ui_interface.launch(share=True, inline=False)
json_interface.launch(share=True, inline=False)

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, roc_curve, auc, precision_recall_curve, f1_score



"""**ANALYSIS REPORT**"""

# Confusion Matrix for Fake vs. Real Classifier
def plot_confusion_matrix(y_true, y_pred, title):
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(5, 4))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title(title)
    plt.ylabel('Actual')
    plt.xlabel('Predicted')
    plt.show()

plot_confusion_matrix(y_test, y_pred_rf, "Fake vs. Real Classifier")

# 2. Precision, Recall, and F1-Score for Both Models
print("Fake vs. Real Classifier Report:\n", classification_report(y_test, y_pred_rf))
print("Sentiment Classifier Report:\n", classification_report(y_test_s, y_pred_sent))

# 3. Balanced Accuracy Score
print(f"Balanced Accuracy (Fake vs. Real): {balanced_accuracy_score(y_test, y_pred_rf):.4f}")

#PRECISION,RECALL AND F1 SCORE
from sklearn.metrics import precision_score, recall_score, f1_score

precision_rf = precision_score(y_test, y_pred_rf)
recall_rf = recall_score(y_test, y_pred_rf)
f1_rf = f1_score(y_test, y_pred_rf)

print(f"Precision: {precision_rf:.2f}")
print(f"Recall: {recall_rf:.2f}")
print(f"F1 Score: {f1_rf:.2f}")

import matplotlib.pyplot as plt
from sklearn.metrics import precision_recall_curve, auc

# Predict probabilities for the test set
y_scores = rf_classifier.predict_proba(X_test)[:, 1]

# Compute precision, recall, and thresholds
precision, recall, thresholds = precision_recall_curve(y_test, y_scores)
pr_auc = auc(recall, precision)

# Plotting the Precision-Recall Curve
plt.figure(figsize=(8, 6))
plt.plot(recall, precision, label=f'PR Curve (AUC = {pr_auc:.2f})')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve for Fake vs. Real Classifier')
plt.legend()
plt.grid(True)
plt.show()

# CLASS DISTRIBUTION
plt.figure(figsize=(6, 4))
sns.countplot(x='Fake_Real_Label', data=df, palette='coolwarm')
plt.title("Class Distribution: Fake vs Real Reviews")
plt.xlabel("Class (0 = Fake, 1 = Real)")
plt.ylabel("Count")
plt.show()

# ROC CURVE

fpr, tpr, _ = roc_curve(y_test, rf_classifier.predict_proba(X_test)[:, 1])
plt.plot(fpr, tpr, label=f'AUC: {auc(fpr, tpr):.2f}')
plt.title('ROC Curve - Fake vs Real Classifier')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend()
plt.show()

# ROC Curve for Sentiment Classifier
fpr_sent, tpr_sent, _ = roc_curve(y_test_s, sentiment_classifier.predict_proba(X_test_s)[:, 1])
plt.plot(fpr_sent, tpr_sent, label=f'Sentiment Classifier (AUC: {auc(fpr_sent, tpr_sent):.2f})')

# Common Plot Settings
plt.title('ROC Curves - Fake vs Real & Sentiment Classifiers')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend()
plt.grid(True)
plt.show()

# Feature Importance for RandomForestClassifier
plt.figure(figsize=(8, 6))
feature_importances_rf = pd.Series(rf_classifier.feature_importances_, index=tfidf.get_feature_names_out()).nlargest(15)
feature_importances_rf.plot(kind='barh')
plt.title("Top 15 Important Features (RandomForest)")
plt.show()

# 10. Feature Importance for XGBClassifier
plt.figure(figsize=(8, 6))
feature_importances_xgb = pd.Series(sentiment_classifier.feature_importances_, index=tfidf.get_feature_names_out()).nlargest(15)
feature_importances_xgb.plot(kind='barh', color='purple')
plt.title("Top 15 Important Features (XGBClassifier)")
plt.show()

!pip install gradio